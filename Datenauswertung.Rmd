---
title: "R Notebook"
output: html_notebook
---

# .............................................................................. ----
# style [Style Regeln, damit unser Code gleich aussieht und von allen gelesen werden kann]

```{r}

# First of all some style rules. Headers get # and a line # ...... ---- above
# it, Subheaders get ##, subsubheaders get ###. All headers get ---- at the end
# so that they are foldable. Collapse all with Alt+o to see its beauty
# (Alt+Shift+o to expand all afterwards) Regular comments that are not headers
# get a single #

## about spacing

#bad
# good


## Two blank lines before each header you can fold and one afterwards ----

# one blank line after each header. No blank lines after a normal comment
bad<-"bad"
good <- "good"

# one blank before each comment.

# Vor und nach ``` Leerzeichen lassen

```

# .............................................................................. ----
# load packages & checkpoint

```{r}

if(!require("checkpoint")){install.packages("checkpoint")}; library("checkpoint") # this solves the problem of package reproducibility. It saves current versions of the scripts you use.

checkpoint("2020-11-03",
             checkpointLocation = getwd())

if(!require("tidyverse")){install.packages("tidyverse")}; library("tidyverse")
if(!require("ggplot2")){install.packages("ggplot2")}; library("ggplot2") # plots
if(!require("lubridate")){install.packages("lubridate")}; library("lubridate") # Umgang mit Datum
if(!require("readr")){install.packages("readr")}; library("readr") # Einlesen von Daten
if(!require("dplyr")){install.packages("dplyr")}; library("dplyr") # Einlesen von 
if(!require("e1071")){install.packages("e1071")}; library("e1071") # Support Vektor Machines
if(!require("Metrics")){install.packages("Metrics")}; library("Metrics") # Support Vektor Machines

```

# .............................................................................. ----
# load data [hier gehts los]

```{r}

umsatzdaten <- read_csv("raw_data/umsatzdaten_gekuerzt.csv")
kiwo <- read_csv("raw_data/kiwo.csv")
wetter <- read_csv("raw_data/wetter.csv")

```

# .............................................................................. ----
# Datensätze strukturieren und auf Fehler untersuchen [hier gehts los]

weitere Fragem an den Datensatz:
Sind alle Tage enthalten oder gibt es auch Tage die nicht enthalten sind? Gibt es Wochen an denen frei/kein umsatz war/ist?


```{r}

## Überprüfen auf NA 
which(is.na(umsatzdaten==TRUE))
which(is.na(kiwo==TRUE))
which(is.na(wetter==TRUE))

# Es gibt NAs im wetter Datensatz, in den beiden anderen nicht.

```

```{r}

## Erweitern des Umsatzdaten Datensates mit Wochentagen
umsatzdaten$weekday <- wday(umsatzdaten$Datum) # 1 ist Sonntag. Meine ich.

## Wetter an den Datensatz anschließen
umsatzdaten <- merge(umsatzdaten, wetter, by = "Datum")

## Umsatz des Vortages zufügen -> Vorsicht mit Warengruppe!
umsatzdaten %>% group_by(weekday) # klappt so nicht. Muss mit Group_by gemacht werde

```

# .............................................................................. ----
# Lineare Regression 


```{r}

q <- lm( formula = Umsatz ~ Temperatur + Wettercode ,data = umsatzdaten)
summary(q)

```


# .............................................................................. ----
# Support Vektor Machine Analysis

## TODO
Hier sind noch die Fragen offen: Welche Variablen sollten wir setzen?


## Aufteilung des Datensatzes in Trainings- und Testdaten

```{r}
# Zufallszähler setzen (um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten)
set.seed(1)

# Zufällige Ziehung von Indizes für die Zeilen des Datensatzes, die dem Traininsdatensatz zugeordnet werden
indices_train <- sample(seq_len(nrow(umsatzdaten)), size = floor(0.80 * nrow(umsatzdaten)))

# Definition des Trainings- und Testdatensatz durch Selektion bzw. Deselektion der entsprechenden Datenzeilen
train_dataset <- train_dataset_org <- umsatzdaten[indices_train, ]
test_dataset <- umsatzdaten[-indices_train, ]
```


## Data Preparation

```{r}
train_dataset <- sample_frac(train_dataset_org, .10)
```


## Training the SVM

```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Umsatz ~ Bewoelkung, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ Bewoelkung + Temperatur + Windgeschwindigkeit + weekday, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3))) #was machen mit ranges? Andere Werte wählen?
```


## Checking the Prediction Quality


### Trainig Data

SVM without cross validation and grid Search
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(model_svm, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)

```

SVM with cross validation and grid Search
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)
```

### Test Data

SVM without cross validation and grid Search
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(model_svm, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

SVM with cross validation and grid Search
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

# .............................................................................. ----
# Merkliste für nützliche Funktionen

```{r}

glance() # um Parameter von lm() in Tabelle zu oacken
mape () # Fehler berechnen

```
