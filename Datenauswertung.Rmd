---
title: "R Notebook"
output: html_notebook
---

# .............................................................................. ----
# style [Style Regeln, damit unser Code gleich aussieht und von allen gelesen werden kann]

```{r}

# First of all some style rules. Headers get # and a line # ...... ---- above
# it, Subheaders get ##, subsubheaders get ###. All headers get ---- at the end
# so that they are foldable. Collapse all with Alt+o to see its beauty
# (Alt+Shift+o to expand all afterwards) Regular comments that are not headers
# get a single #

## about spacing

#bad
# good


## Two blank lines before each header you can fold and one afterwards ----

# one blank line after each header. No blank lines after a normal comment
bad<-"bad"
good <- "good"

# one blank before each comment.

# Vor und nach ``` Leerzeichen lassen

```

# .............................................................................. ----
# load packages & checkpoint

```{r}

if(!require("checkpoint")){install.packages("checkpoint")}; library("checkpoint") # this solves the problem of package reproducibility. It saves current versions of the scripts you use.

# checkpoint("2020-11-03", checkpointLocation = getwd())

if(!require("tidyverse")){install.packages("tidyverse")}; library("tidyverse")
if(!require("ggplot2")){install.packages("ggplot2")}; library("ggplot2") # plots
if(!require("lubridate")){install.packages("lubridate")}; library("lubridate") # Umgang mit Datum
if(!require("readr")){install.packages("readr")}; library("readr") # Einlesen von Daten
if(!require("dplyr")){install.packages("dplyr")}; library("dplyr") # Einlesen von 
if(!require("e1071")){install.packages("e1071")}; library("e1071") # Support Vektor Machines
if(!require("Metrics")){install.packages("Metrics")}; library("Metrics") # Support Vektor Machines

```

# .............................................................................. ----
# load data [hier gehts los]

```{r}

umsatzdaten <-read_csv("raw_data/umsatzdaten_gekuerzt.csv")
kiwo <- read_csv("raw_data/kiwo.csv")
wetter <- read_csv("raw_data/wetter.csv")
uebernachtungen <- read.csv("raw_data/Uebernachtungen_Kiel_Mai-August_2019.CSV",sep = ";")
holstenstrasse <- read.csv("raw_data/kiel-holstenstrasse_2020.csv", sep = ";")
```

# .............................................................................. ----
# Datensätze strukturieren und auf Fehler untersuchen [hier gehts los]

weitere Fragem an den Datensatz:
Sind alle Tage enthalten oder gibt es auch Tage die nicht enthalten sind? Gibt es Wochen an denen frei/kein umsatz war/ist?


```{r}

## Überprüfen auf NA 
which(is.na(umsatzdaten==TRUE))
which(is.na(kiwo==TRUE))
which(is.na(wetter==TRUE))

# Es gibt NAs im wetter Datensatz, in den beiden anderen nicht.

```

```{r}

## Erweitern des Umsatzdaten Datensates mit Wochentagen
umsatzdaten$weekday <- wday(umsatzdaten$Datum) # 1 ist Sonntag. Meine ich.

## Wetter an den Datensatz anschließen
umsatzdaten <- merge(umsatzdaten, wetter, by = "Datum")

## Umsatz des Vortages zufügen -> Vorsicht mit Warengruppe!
umsatzdaten %>% group_by(weekday) # klappt so nicht. Muss mit Group_by gemacht werde

```

# .............................................................................. ----
# Lineare Regression 
```{r}

```


```{r}

q <- lm( formula = Umsatz ~ Temperatur + Wettercode ,data = umsatzdaten)
summary(q)

```


# .............................................................................. ----
# Support Vektor Machine Analysis

## TODO
Hier sind noch die Fragen offen: Welche Variablen sollten wir setzen?


## Aufteilung des Datensatzes in Trainings- und Testdaten

```{r}
# Zufallszähler setzen (um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten)
set.seed(1)

# Zufällige Ziehung von Indizes für die Zeilen des Datensatzes, die dem Traininsdatensatz zugeordnet werden
indices_train <- sample(seq_len(nrow(umsatzdaten)), size = floor(0.80 * nrow(umsatzdaten)))

# Definition des Trainings- und Testdatensatz durch Selektion bzw. Deselektion der entsprechenden Datenzeilen
train_dataset <- train_dataset_org <- umsatzdaten[indices_train, ]
test_dataset <- umsatzdaten[-indices_train, ]
```


## Data Preparation

```{r}
train_dataset <- sample_frac(train_dataset_org, .10)
```


## Training the SVM

```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Umsatz ~ Bewoelkung, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ Bewoelkung + Temperatur + Windgeschwindigkeit + weekday, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3))) #was machen mit ranges? Andere Werte wählen?
```


## Checking the Prediction Quality


### Trainig Data

SVM without cross validation and grid Search
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(model_svm, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)

```

SVM with cross validation and grid Search
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)
```

### Test Data

SVM without cross validation and grid Search
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(model_svm, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

SVM with cross validation and grid Search
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

#...............................................................................----
# Neuronales Netzt

## Python Schnittstelle

```{r}
install.packages("reticulate")
library(reticulate)

# Installation von miniconda (falls nicht vorhanden)
#install_miniconda(update=TRUE)

# Anlegen einer speziellen Python Umgebung
conda_create("r-reticulate")

# Installieren der Pakete in der angelegten Umgebung
conda_install("r-reticulate", "pandas")
conda_install("r-reticulate", "numpy")
conda_install("r-reticulate", "tensorflow")
conda_install("r-reticulate", "h5py")
 
# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")

```

## Einlesen der Aufbereiteten Daten aus seperatem Skript

```{r}
source("umsatzdaten")
```

## Definition des Neuronalen Netzes
```{python}
# Benoetigte Python Libraries einbinden
import numpy as np
import tensorflow as tf
from tensorflow import keras

# Definition der Form des tiefen neuronalen Netzes (Deep Neural Net)
model = tf.keras.Sequential([
  keras.layers.Dense(10, activation='relu', input_shape=[len(r.train_dataset.keys())]),
  keras.layers.Dense(4, activation='relu'),
  keras.layers.Dense(1)
])

# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model.compile(loss="mse", optimizer=tf.keras.optimizers.Adam(0.001))

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model.summary()
```

#...............................................................................----
# Schätzung des neuronalen Netzes / was sind die Test_labels in unserem bereinigten Datensatz?

```{python}
# Schaetzung des Modells
history = model.fit(r.train_dataset, r.train_labels, epochs=150,
                    validation_data = (r.test_dataset, r.test_labels), verbose=0)

# Ggf. Speichern des geschaetzten Modells
model.save("python_model.h5")

```


## Auswertung der Modell optimierung / Fehlt history aus der Schätzung des neuronalen Netztes!

```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data <- data.frame(val_loss = unlist(py$history$history$val_loss),
                  loss = unlist(py$history$history$loss))

# Plot
ggplot(data[-1,]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 

```


## Auswertung der Schätzergebnisse / Fehlt die Schätzung aus Zeile 243

```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
train_predictions_norm <- py$model$predict(train_dataset)
test_predictions_norm <- py$model$predict(test_dataset)

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions <- (train_predictions_norm * norm_values_list$sd[1] ) + norm_values_list$mean[1]
test_predictions <- (test_predictions_norm * norm_values_list$sd[1]) + norm_values_list$mean[1]
# Selektion der zugehörigen tatsächlichen Preise
train_actuals <- house_pricing$price[train_ind]
test_actuals <- house_pricing$price[-train_ind]


# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(train_actuals, train_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(test_actuals, test_predictions)*100, digits=3, nsmall=2)))

```


```{r}
## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = train_predictions/1000, actual = train_actuals/1000)
data_test <- data.frame(prediction = test_predictions/1000, actual = test_actuals/1000)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Price in 1.000 USD") 

# Plot der Ergebnisse der Testdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Price in 1.000 USD") 
```

#................................................................................----
# Vorhersage für einen einzelnen Fall

```{r}
# Vorhersage für einen einzelnen Fall
cat(paste0("Vorhergesagter Preis:\t", round(test_predictions[100])))
cat(paste0("\nTatsächlicher Preis:\t", test_actuals[100]))
```



.......................................
# .............................................................................. ----
# Merkliste für nützliche Funktionen

```{r}

glance() # um Parameter von lm() in Tabelle zu oacken
mape () # Fehler berechnen

```